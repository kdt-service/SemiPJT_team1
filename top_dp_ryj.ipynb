{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### íƒ‘ë¦¬ë·°ì–´ df\n",
    "\n",
    "ì‘ì„±ì, ì£¼ë¬¸ ë‚ ì§œ, ë¦¬ë·° ì‘ì„± ë‚ ì§œ, ë¦¬ë·° ë‚´ìš©, ë¦¬ë·°ë‹¹ â€˜ë„ì›€ì´ ë¼ìš”â€™ ê°œìˆ˜, í•œë‹¬ ì´ìƒ ì‚¬ìš©, ì¬êµ¬ë§¤ ì—¬ë¶€, ì‚¬ì§„ ê°œìˆ˜, ì œí’ˆ êµ¬ë§¤ ë°©ë²•, ë¦¬ë·° ê³ ìœ ë²ˆí˜¸, í‰ì (ê¸ë¶€ì •)\n",
    "ë¦¬ë·° ì“´ ì£¼ê¸°, ë¦¬ë·° ê¸¸ì´, ì´ â€˜ë„ì›€ì´ ë¼ìš”â€™, ë¦¬ë·°ë‹¹ â€˜ë„ì›€ì´ ë¼ìš”â€™ (í‰ê· ), ì²´í—˜ë‹¨ ë¦¬ë·°ì™€ ì¼ë°˜ ë¦¬ë·° ì°¨ì´ (ë¦¬ë·° ê¸¸ì´ í¸ì°¨)\n",
    "\n",
    "- gdasSeq  :  ë¦¬ë·° ê³ ìœ ë²ˆí˜¸\n",
    "- gdasScrVal: í‰ì  (2,4,6,8,10)\n",
    "- dispRegDate : ë¦¬ë·° ì—…ë¡œë“œ ë‚ ì§œ\n",
    "- gdasCont : ë¦¬ë·° ë³¸ë¬¸\n",
    "- ordDate: ìƒí’ˆ ì£¼ë¬¸ ë‚ ì§œ\n",
    "- photoList: ì‚¬ì§„ ë¦¬ìŠ¤íŠ¸ (ì‚¬ì§„ ì—†ìœ¼ë©´ null)\n",
    "- recommCnt: ë„ì›€ì´ ë¼ìš” ê°œìˆ˜\n",
    "- renewUsed1mmGdasYn: í•œë‹¬ì´ìƒ ì‚¬ìš©\n",
    "- firstGdasYn: ì²« êµ¬ë§¤ ì—¬ë¶€ (ì¬êµ¬ë§¤ë©´ â€œNâ€ ì•„ë‹ˆë©´ â€œYâ€)\n",
    "- mbrNo: ë¦¬ë·°ë¥¼ ì‘ì„±í•œ íšŒì›ì˜ ê³ ìœ  ì‹ë³„ì\n",
    "- gdasSctCd : ì œí’ˆ êµ¬ë§¤ ë°©ë²• (10 - ì˜¨ë¼ì¸, 60 - ë§¤ì¥, 50 - ì²´í—˜ë‹¨, 70 - ì„ ë¬¼)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/w592whfs2tb4g8s658288fb00000gn/T/ipykernel_50605/3744978623.py:3: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  top_df = pd.read_csv(topReviews_path, header=0, encoding='UTF-8')\n"
     ]
    }
   ],
   "source": [
    "# íƒ‘ë¦¬ë·°ì–´ ì •ë³´ DFë¡œ ê°€ì ¸ì˜¤ê¸°\n",
    "topReviews_path = '/Users/ryeongjoo/Desktop/workspace/semi_prj/topReviews.csv'\n",
    "top_df = pd.read_csv(topReviews_path, header=0, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ì¹¼ëŸ¼ë§Œ ë‹´ì€ DF\n",
    "my_top_df = top_df[['mbrNo','ordDate','dispRegDate','gdasCont','recommCnt','renewUsed1mmGdasYn','firstGdasYn', 'gdasSeq', 'gdasScrVal','gdasSctCd' ]]\n",
    "# print(my_top_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN ê°’ ë“œë\n",
    "my_top_df = my_top_df.dropna(subset=['gdasCont'])\n",
    "\n",
    "# ì˜ì–´ ì†Œë¬¸ì í†µì¼\n",
    "my_top_df['gdasCont'] = my_top_df['gdasCont'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ê·œì‹ì„ ì´ìš©í•˜ì—¬ ì´ëª¨í‹°ì½˜ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
    "def extract_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001f600-\\U0001f64f\"  # ì´ëª¨í‹°ì½˜\n",
    "        u\"\\U0001f300-\\U0001f5ff\"  # ê¸°í˜¸ ë° ë¬¸ì¥ ë¶€í˜¸\n",
    "        u\"\\U0001f680-\\U0001f6ff\"  # ê¸°íƒ€ ì´ëª¨í‹°ì½˜\n",
    "        u\"\\U0001f1e0-\\U0001f1ff\"  # êµ­ê¸° ë° ê¸°í˜¸\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.findall(text)\n",
    "\n",
    "# 'ì´ëª¨í‹°ì½˜' ì—´ ìƒì„±\n",
    "my_top_df['unicode'] = my_top_df['gdasCont'].apply(lambda x: extract_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¦¬ë·°ë‚´ìš© ì¤‘ë³µë¬¸ì, ì´ëª¨í‹°ì½˜ ì œê±°\n",
    "clean_reviews = []\n",
    "emoticon_list = []\n",
    "\n",
    "def remove_emoji(text):\n",
    "    # ì´ëª¨í‹°ì½˜ íŒ¨í„´ ì •ì˜\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # ì´ëª¨í‹°ì½˜\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # ì‹¬ë³¼\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # íŠ¸ëœìŠ¤í¬íŠ¸ ë° ì§€ë„\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # êµ­ê¸° ë° ì´ëª¨ì§€\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    # ì´ëª¨í‹°ì½˜ ì œê±°\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "for review in my_top_df['gdasCont'] :\n",
    "    \n",
    "    # ì´ˆì„±, ì¤„ë°”ê¿ˆ ì œê±°\n",
    "    review = re.sub('[ã„±-ã…ã…-ã…£]', '', review)\n",
    "    review = re.sub('[\\r\\n]', ' ', review)  \n",
    "    \n",
    "    # ì´ëª¨í‹°ì½˜ ì œê±°\n",
    "    review = remove_emoji(review)\n",
    "    \n",
    "    clean_reviews.append(review)\n",
    "    \n",
    "my_top_df['gdasCont'] = clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¦¬ë·° ê¸¸ì´ ì¹¼ëŸ¼ ì¶”ê°€\n",
    "my_top_df['cont_length'] = my_top_df['gdasCont'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# print(my_top_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¦¬ë·° ì£¼ê¸° ì¹¼ëŸ¼\n",
    "# ë¦¬ë·° ì‘ì„± ë‚ ì§œ - êµ¬ë§¤ì¼ì\n",
    "\n",
    "# ë‚ ì§œí˜•ìœ¼ë¡œ ë³€í™˜\n",
    "my_top_df['dispRegDate'] = pd.to_datetime(my_top_df['dispRegDate'])\n",
    "my_top_df['ordDate'] = pd.to_datetime(my_top_df['ordDate'])\n",
    "\n",
    "# NaNì´ ì•„ë‹Œ í–‰ ì„ íƒ\n",
    "subset = my_top_df[my_top_df['ordDate'].notnull() ]\n",
    "\n",
    "# ë‘ ë‚ ì§œì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ì—¬ ìƒˆë¡œìš´ ì¹¼ëŸ¼ì— ì¶”ê°€\n",
    "my_top_df.loc[subset.index, 'or_diff'] = my_top_df['dispRegDate'] - my_top_df['ordDate']\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "# print(my_top_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë¦¬ë·°ì–´ë³„ df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mbrNo ì¹¼ëŸ¼ ìƒì„±\n",
    "unique_mbrNo = my_top_df['mbrNo'].unique()  # ì¤‘ë³µì„ ì œê±°í•œ mbrNo ê°’ ì¶”ì¶œ\n",
    "reviewer_df['mbrNo'] = pd.Series(unique_mbrNo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¦¬ë·°ì–´ë³„ ì´ ë„ì›€ì´ ë¼ìš” ê°œìˆ˜\n",
    "\n",
    "# ì´ ë¦¬ë·° ê°œìˆ˜ ê³„ì‚°\n",
    "recommSum_df = my_top_df.groupby('mbrNo')['recommCnt'].sum().reset_index().rename(columns={'recommCnt': 'total_recomm'})\n",
    "\n",
    "# reviewer_dfì™€ recommSum_df ì¡°ì¸\n",
    "reviewer_df = pd.merge(reviewer_df, recommSum_df, on='mbrNo', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¦¬ë·°ì–´ë³„ ì‘ì„± ë¦¬ë·° ê°œìˆ˜\n",
    "reviewCnt_df = my_top_df.groupby('mbrNo')['gdasCont'].count().reset_index().rename(columns={'gdasCont': 'gdas_cnt'})\n",
    "reviewer_df = pd.merge(reviewer_df, reviewCnt_df, on='mbrNo', how='left')\n",
    "\n",
    "# ë¦¬ë·°ì–´ë³„ ë¦¬ë·° ê°œìˆ˜ë‹¹ í‰ê·  ë„ì›€ì´ ë¼ìš” ê°œìˆ˜\n",
    "reviewer_df['recomm_mean'] = reviewer_df['total_recomm'] / reviewer_df['gdas_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¦¬ë·°ì–´ë³„ ì²´í—˜ë‹¨ ë¦¬ë·°ì™€ ì¼ë°˜ ë¦¬ë·° ì°¨ì´ (ë¦¬ë·° ê¸¸ì´ í¸ì°¨)\n",
    "\n",
    "# ì²´í—˜ë‹¨ ë¦¬ë·°ê¸¸ì´ í‰ê· \n",
    "test_df = my_top_df.loc[my_top_df['gdasSctCd'] == 50].groupby('mbrNo')['cont_length'].mean()\n",
    "\n",
    "# ì²´í—˜ë‹¨ ì œì™¸í•œ ë¦¬ë·° ê¸¸ì´ í‰ê· \n",
    "buy_df = my_top_df.loc[my_top_df['gdasSctCd'] != 50].groupby('mbrNo')['cont_length'].mean()\n",
    "\n",
    "# ì²´í—˜ë‹¨ ë¦¬ë·°ê¸¸ì´ - ì²´í—˜ë‹¨ ì œì™¸í•œ ë¦¬ë·° ê¸¸ì´ \n",
    "diff_df = pd.DataFrame({'tb_len_diff': test_df - buy_df}).reset_index()\n",
    "\n",
    "# reviewer_dfì™€ recommSum_df ì¡°ì¸\n",
    "reviewer_df = pd.merge(reviewer_df, diff_df, on='mbrNo', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mbrNo</th>\n",
       "      <th>total_recomm</th>\n",
       "      <th>gdas_cnt</th>\n",
       "      <th>recomm_mean</th>\n",
       "      <th>tb_len_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0000004535694</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>300</td>\n",
       "      <td>3.393333</td>\n",
       "      <td>222.132203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M0000012163234</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>80</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>310.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M0000016082816</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>110</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>222.391509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M0000003453847</td>\n",
       "      <td>604.0</td>\n",
       "      <td>100</td>\n",
       "      <td>6.040000</td>\n",
       "      <td>249.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M0000010425691</td>\n",
       "      <td>765.0</td>\n",
       "      <td>100</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>36.406250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mbrNo  total_recomm  gdas_cnt  recomm_mean  tb_len_diff\n",
       "0  M0000004535694        1018.0       300     3.393333   222.132203\n",
       "1  M0000012163234        1216.0        80    15.200000   310.120000\n",
       "2  M0000016082816        1177.0       110    10.700000   222.391509\n",
       "3  M0000003453847         604.0       100     6.040000   249.791667\n",
       "4  M0000010425691         765.0       100     7.650000    36.406250"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ì œê°€ ìµœê·¼ì— ì˜¬ë¦¬ë¸Œì˜ì—ì„œ ê°€ì¥ ë§ì´êµ¬ë§¤ë¥¼ í–ˆë˜ ì œí’ˆì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤ì‹ ë‘ì´ 30gì§œë¦¬ë¥¼ ...\n",
       "1    í—ˆë¸Œì íŠ¸ ë¯¹ìŠ¤ë„›ì€ ê²¬ê³¼ë¥˜êµ¬ì„±ì€ë§˜ì— ë“œëŠ”ë° ë„˜ì§œìš”ã… ê·¸ë˜ë„ 1+1 í–‰ì‚¬ë¥¼ í•˜ê¸¸ë˜ êµ¬ë§¤ë¥¼...\n",
       "2    ì•„ì¹¨ì— ì£¼ë¡œ ë§ˆì‹œê³  ìˆëŠ” ì‚¬ê³¼ë‹¹ê·¼ë§›ì´ë„ˆì£¼ìŠ¤ì…ë‹ˆë‹¤ì œê°€ 5ë…„ì„ ë„˜ê²Œ ë§ˆì‹œê³  ìˆëŠ”ë° ê¾¸ì¤€...\n",
       "3    ì‹ ë‘ì„ ì¤„ë ¤ê³  ì‹ ì²­ì„ í–ˆì–´ìš”ë‹¤ë¹„ë„í”„ í–¥ìˆ˜ëŠ” í”„ë‘ìŠ¤ì—ì„œ ë§Œë“¤ì–´ì¡Œê³  í–¥ìˆ˜ë³‘ì€ ë„¤ëª¨ë‚œ í˜•...\n",
       "4              íŒ½ì´ë²„ì„¯ ìœ ì‚°ê·  ë°œíš¨ì•¡ì´ ë“¤ì–´ê°€ì„œê¾¸ì¤€í•˜ê²Œ ë§ˆì‹œë©´ í™”ì¥ì‹¤ ê°€ëŠ”ê²Œí¸í•´ì§€ë„¤ìš”\n",
       "5    ìµœê·¼ì— ì˜¬ë¦¬ë¸Œì˜ì—ì„œ ì œì¼ ë§ì´êµ¬ë§¤ë¥¼ í–ˆë˜ ì œí’ˆì…ë‹ˆë‹¤ì‹ ë‘ì´ ê±°ì˜ ë§¤ì¼ 30gì§œë¦¬ë¥¼ ë‘...\n",
       "6    ì…ìê°€ ì •ë§ ê³ ì™€ìš”í„ê°ë„ ì ë‹¹í•˜ê³  ì •ë§ ê´œì°®ì€ë“¯ í•©ë‹ˆë‹¤ë¬´ì—‡ë³´ë‹¤ ê°€ë£¨ë‚ ë¦¼ì´ ì—†ì–´ì„œ ë§˜...\n",
       "7    ì•„ì¹¨ì— ì£¼ë¡œ ë§ˆì‹œê³  ìˆëŠ” ì‚¬ê³¼ë‹¹ê·¼ë§›ì´ë„ˆì£¼ìŠ¤ì…ë‹ˆë‹¤ì´ë„ˆì£¼ìŠ¤ëŠ” í”„ë£¬ë§›ê³¼ ì‚¬ê³¼ë‹¹ê·¼ë§› ë‘ê°€ì§€...\n",
       "8            ì´ë„ˆì£¼ìŠ¤ì¤‘ ì œê°€ ì œì¼ ì¢‹ì•„í•˜ëŠ”í”„ë£¬ë§›ì…ë‹ˆë‹¤120mlë¼ì„œ ì¢€ ì•„ì‰¬ìš¸ë•Œë„ ìˆì–´ìš”\n",
       "9    ì‹ ë‘ì´ ê±°ì˜ë§¤ì¼ 30gì§œë¦¬ë‘ë´‰ì§€ì”© ë¨¹ê³ ìˆì–´ìš”ê·¸ë˜ì„œ ì˜¬ë¦¬ë¸Œì˜ì—ì„œ 1+1í–‰ì‚¬ë¥¼í• ë•Œ ê³„ì†...\n",
       "Name: gdasCont, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def text_len(text):\n",
    "    return re.sub('[^ã…-ã…£ê°€-í£ .,+â€¦\\';:\\-ã†\\(\\)&0-9A-Za-z]+', '', text)\n",
    "my_top_df['gdasCont'][:10].apply(text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            mbrNo  total_recomm  gdas_cnt  recomm_mean  tb_len_diff\n",
      "0  M0000004535694        1018.0       300     3.393333   222.132203\n",
      "1  M0000012163234        1216.0        80    15.200000   310.120000\n",
      "2  M0000016082816        1177.0       110    10.700000   222.391509\n",
      "3  M0000003453847         604.0       100     6.040000   249.791667\n",
      "4  M0000010425691         765.0       100     7.650000    36.406250\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë¦¬ë·° ë‚´ìš© í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ì œ', 'ìµœê·¼', 'ì˜¬ë¦¬ë¸Œì˜', 'ê°€ì¥', 'ë§ì´', 'êµ¬ë§¤', 'í–ˆë˜', 'ì œí’ˆ', 'ì¤‘', 'í•˜ë‚˜', 'ì…ë‹ˆë‹¤', 'ì‹ ë‘', '30', 'g', 'ì§œ', 'ë¦¬', 'í•˜ë£¨', 'ë‘', 'ë´‰ì§€', 'ì”©', 'ë¨¹ë„¤', 'ìš”í•˜', 'ì œì…', 'ë§ì´', 'ë‹¬ì•„ìš”'], ['í—ˆë¸Œ', 'ì íŠ¸', 'ë¯¹ìŠ¤ë„›', 'ê²¬ê³¼ë¥˜', 'êµ¬ì„±ì€', 'ë§˜', 'ë“œëŠ”ë°', 'ë„˜', 'ì§œìš”', 'ê·¸ë˜ë„', '1', '1', 'í–‰ì‚¬', 'í•˜ê¸¸ë˜', 'êµ¬ë§¤', 'í–ˆëŠ”ë°', 'ê²‰', 'ë¬»ì€', 'ê°€ë£¨', 'í„¸ì–´ë‚´ê³ ', 'ë¨¹ì–´ì•¼', 'í•´'], ['ì•„ì¹¨', 'ì£¼ë¡œ', 'ë§ˆì‹œê³ ', 'ìˆëŠ”', 'ì‚¬ê³¼', 'ë‹¹', 'ê·¼', 'ë§›', 'ì´', 'ë„ˆ', 'ì£¼ìŠ¤', 'ì…ë‹ˆë‹¤', 'ì œ', '5ë…„', 'ì„', 'ë„˜ê²Œ', 'ë§ˆì‹œê³ ', 'ìˆëŠ”ë°', 'ê¾¸ì¤€í•˜ê²Œ', 'ë§ˆì‹œë©´', 'í™”ì¥ì‹¤', 'ê°€ëŠ”ê²Œ', 'í¸í•´ì ¸ì„œ', 'ì¢‹ì•„ìš”'], ['ì‹ ë‘', 'ì¤„ë ¤ê³ ', 'ì‹ ì²­', 'í–ˆì–´ìš”', 'ë‹¤ë¹„ë„í”„', 'í–¥ìˆ˜', 'í”„ë‘ìŠ¤', 'ë§Œë“¤ì–´ì¡Œê³ ', 'í–¥ìˆ˜ë³‘', 'ë„¤ëª¨', 'í˜•íƒœ', 'ë˜ì–´ìˆê³ ', 'ì¡ê¸°', 'í¸í•˜ë„¤ìš”', 'ì œí’ˆ', 'ë°›ê³ ', 'ë°”ë¡œ', 'ì‹ ë‘', 'ë¿Œë ¤', 'ë´¤ëŠ”ë°', 'í–¥', 'ë”±', 'ë‚¨ì', 'ë“¤', 'ì¢‹ì•„í• ë§Œ', 'í•œ', 'í–¥', 'ìš”', 'ì¼ë‹¨', 'í–¥', 'ì¤‘ìš”í•˜ì§€ë§Œ', 'ì§€ì†', 'ë ¥', 'ì¢‹ì•„ì•¼', 'í•´ì„œ', 'ì‹ ë‘', 'ë¿Œë¦¬', 'í•œë‘', 'ì‹œê°„', 'ì§€ë‚˜ì„œë„', 'í–¥', 'ë‚˜ëŠ”ì§€', 'ì˜†', 'ê°€ë´¤ë”ë‹ˆ', 'ì§„í•˜ê²ŒëŠ”ì•„ë‹ˆì§€ë§Œ', 'ì€ì€í•˜ê²Œ', 'ì”í–¥', 'ë‚¨ì•„', 'ìˆëŠ”ë“¯', 'í•˜ë„¤ìš”', 'ğŸ˜', 'ë‚ ì”¨', 'ì ì ', 'ë”ì›Œì§€ëŠ”ë°', 'ì—¬ë¦„', 'ë¿Œë ¤ë„', 'ì¢‹ì„ê²ƒ', 'ê°™ë‹¤ëŠ”', 'ìƒê°', 'ë“œ', 'ë„¤', 'ë‚˜ì´', 'ìƒê´€ì—†ì´', 'ëª¨ë“ ', 'ì—°ë ¹', 'ì¸µ', 'ì‚¬ìš©', 'í•˜ê¸°ì—', 'ê´œì°®ì€', 'ì œí’ˆ', 'ë“¯', 'í•©ë‹ˆë‹¤', 'ğŸ‘'], ['íŒ½ì´ë²„ì„¯', 'ìœ ì‚°ê· ', 'ë°œíš¨', 'ì•¡', 'ë“¤ì–´ê°€ì„œ', 'ê¾¸ì¤€í•˜ê²Œ', 'ë§ˆì‹œë©´', 'í™”ì¥ì‹¤', 'ê°€ëŠ”ê²Œ', 'í¸í•´ì§€ë„¤ìš”']]\n"
     ]
    }
   ],
   "source": [
    "# í† í°í™”\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "\n",
    "tokens_results = []\n",
    "\n",
    "for text in my_top_df['gdasCont'].head(5):\n",
    "    \n",
    "    # Okt ê°ì²´ ìƒì„±\n",
    "    okt = Okt()\n",
    "\n",
    "    # ì´ˆì„±, ì¤„ë°”ê¿ˆ ì œê±°\n",
    "    text = re.sub('[ã„±-ã…ã…-ã…£\\r\\n]', '', text)\n",
    "\n",
    "    tokens = okt.pos(text)\n",
    "    result = []\n",
    "\n",
    "    for word, tag in tokens:\n",
    "        if tag not in ['Josa', 'Eomi', 'Punctuation']:\n",
    "            result.append(word)\n",
    "\n",
    "    tokens_results.append(result)\n",
    "    \n",
    "print(tokens_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['30' 'ê°€ì¥' 'êµ¬ë§¤' 'ë‹¬ì•„ìš”' 'ë§ì´' 'ë¨¹ë„¤' 'ë´‰ì§€' 'ì‹ ë‘' 'ì˜¬ë¦¬ë¸Œì˜' 'ìš”í•˜' 'ì…ë‹ˆë‹¤' 'ì œì…' 'ì œí’ˆ' 'ìµœê·¼'\n",
      " 'í•˜ë‚˜' 'í•˜ë£¨' 'í–ˆë˜']\n",
      "['ê°€ë£¨' 'ê²¬ê³¼ë¥˜' 'êµ¬ë§¤' 'êµ¬ì„±ì€' 'ê·¸ë˜ë„' 'ë“œëŠ”ë°' 'ë¨¹ì–´ì•¼' 'ë¬»ì€' 'ë¯¹ìŠ¤ë„›' 'ì íŠ¸' 'ì§œìš”' 'í„¸ì–´ë‚´ê³ ' 'í•˜ê¸¸ë˜'\n",
      " 'í–ˆëŠ”ë°' 'í–‰ì‚¬' 'í—ˆë¸Œ']\n",
      "['5ë…„' 'ê°€ëŠ”ê²Œ' 'ê¾¸ì¤€í•˜ê²Œ' 'ë„˜ê²Œ' 'ë§ˆì‹œê³ ' 'ë§ˆì‹œë©´' 'ì‚¬ê³¼' 'ì•„ì¹¨' 'ì…ë‹ˆë‹¤' 'ìˆëŠ”' 'ìˆëŠ”ë°' 'ì¢‹ì•„ìš”' 'ì£¼ë¡œ'\n",
      " 'ì£¼ìŠ¤' 'í¸í•´ì ¸ì„œ' 'í™”ì¥ì‹¤']\n",
      "['ê°€ë´¤ë”ë‹ˆ' 'ê°™ë‹¤ëŠ”' 'ê´œì°®ì€' 'ë‚˜ëŠ”ì§€' 'ë‚˜ì´' 'ë‚ ì”¨' 'ë‚¨ì•„' 'ë‚¨ì' 'ë„¤ëª¨' 'ë‹¤ë¹„ë„í”„' 'ë”ì›Œì§€ëŠ”ë°' 'ë˜ì–´ìˆê³ '\n",
      " 'ë§Œë“¤ì–´ì¡Œê³ ' 'ëª¨ë“ ' 'ë°”ë¡œ' 'ë°›ê³ ' 'ë´¤ëŠ”ë°' 'ë¿Œë ¤' 'ë¿Œë ¤ë„' 'ë¿Œë¦¬' 'ì‚¬ìš©' 'ìƒê´€ì—†ì´' 'ìƒê°' 'ì‹œê°„' 'ì‹ ë‘'\n",
      " 'ì‹ ì²­' 'ì—¬ë¦„' 'ì—°ë ¹' 'ì€ì€í•˜ê²Œ' 'ì¼ë‹¨' 'ìˆëŠ”ë“¯' 'ì”í–¥' 'ì¡ê¸°' 'ì ì ' 'ì œí’ˆ' 'ì¢‹ì•„ì•¼' 'ì¢‹ì•„í• ë§Œ' 'ì¢‹ì„ê²ƒ'\n",
      " 'ì¤„ë ¤ê³ ' 'ì¤‘ìš”í•˜ì§€ë§Œ' 'ì§€ë‚˜ì„œë„' 'ì§€ì†' 'ì§„í•˜ê²ŒëŠ”ì•„ë‹ˆì§€ë§Œ' 'í¸í•˜ë„¤ìš”' 'í”„ë‘ìŠ¤' 'í•˜ê¸°ì—' 'í•˜ë„¤ìš”' 'í•œë‘' 'í•©ë‹ˆë‹¤'\n",
      " 'í•´ì„œ' 'í–ˆì–´ìš”' 'í–¥ìˆ˜' 'í–¥ìˆ˜ë³‘' 'í˜•íƒœ']\n",
      "['ê°€ëŠ”ê²Œ' 'ê¾¸ì¤€í•˜ê²Œ' 'ë“¤ì–´ê°€ì„œ' 'ë§ˆì‹œë©´' 'ë°œíš¨' 'ìœ ì‚°ê· ' 'íŒ½ì´ë²„ì„¯' 'í¸í•´ì§€ë„¤ìš”' 'í™”ì¥ì‹¤']\n"
     ]
    }
   ],
   "source": [
    "# í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "for documents in tokens_results:\n",
    "\n",
    "    # TfidfVectorizer ê°ì²´ ìƒì„±\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # TfidfVectorizerë¡œ ë¬¸ì„œ ë²¡í„°í™” ìˆ˜í–‰\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "    # get_feature_names() ë©”ì„œë“œë¥¼ ì´ìš©í•´ ë‹¨ì–´ ëª©ë¡ê³¼ ê° ë‹¨ì–´ì˜ ì¸ë±ìŠ¤ í™•ì¸\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "    print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•˜ì§€ë§Œ ì œì…ì—” ë§ì´ ë‹¬ì•„ìš” ì‹ ë‘ì´ 30gì§œë¦¬ë¥¼ í•˜ë£¨ì— ë‘ë´‰ì§€ì”©\n",
      "ë¨¹ë„¤ìš”ã…‹ ì œê°€ ìµœê·¼ì— ì˜¬ë¦¬ë¸Œì˜ì—ì„œ ê°€ì¥ ë§ì´\n",
      "êµ¬ë§¤ë¥¼ í–ˆë˜ ì œí’ˆì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤ã…\n",
      "ê·¸ë˜ë„ 1+1 í–‰ì‚¬ë¥¼ í•˜ê¸¸ë˜ êµ¬ë§¤ë¥¼\n",
      "í–ˆëŠ”ë° ê²‰ì— ë¬»ì€ ê°€ë£¨ë¥¼ í„¸ì–´ë‚´ê³ \n",
      "ë¨¹ì–´ì•¼ í•´ìš” í—ˆë¸Œì íŠ¸ ë¯¹ìŠ¤ë„›ì€ ê²¬ê³¼ë¥˜êµ¬ì„±ì€\n",
      "ë§˜ì— ë“œëŠ”ë° ë„˜ì§œìš”ã… \n",
      "ì œê°€ 5ë…„ì„ ë„˜ê²Œ ë§ˆì‹œê³  ìˆëŠ”ë° ê¾¸ì¤€í•˜ê²Œ\n",
      "ë§ˆì‹œë©´ í™”ì¥ì‹¤ ê°€ëŠ”ê²Œ í¸í•´ì ¸ì„œ ì¢‹ì•„ìš” ì•„ì¹¨ì— ì£¼ë¡œ ë§ˆì‹œê³  ìˆëŠ” ì‚¬ê³¼ë‹¹ê·¼ë§›\n",
      "ì´ë„ˆì£¼ìŠ¤ì…ë‹ˆë‹¤ã…\n",
      "ì‹ ë‘ì„ ì¤„ë ¤ê³  ì‹ ì²­ì„ í–ˆì–´ìš”~ ì¼ë‹¨ í–¥ë„ ì¤‘ìš”í•˜ì§€ë§Œ ì§€ì†ë ¥ë„ ì¢‹ì•„ì•¼\n",
      "í•´ì„œ ì‹ ë‘ì´ ë¿Œë¦¬ê³  í•œë‘ì‹œê°„ ì§€ë‚˜ì„œë„\n",
      "í–¥ì´ ë‚˜ëŠ”ì§€ ì˜†ì— ê°€ë´¤ë”ë‹ˆ ì§„í•˜ê²ŒëŠ”\n",
      "ì•„ë‹ˆì§€ë§Œ ì€ì€í•˜ê²Œ ì”í–¥ì´ ë‚¨ì•„ ìˆëŠ”ë“¯\n",
      "í•˜ë„¤ìš”ğŸ˜ ë‚˜ì´ì™€ ìƒê´€ì—†ì´ ëª¨ë“  ì—°ë ¹ì¸µì´ ì‚¬ìš©í•˜ê¸°ì—\n",
      "ê´œì°®ì€ ì œí’ˆì¸ë“¯ í•©ë‹ˆë‹¤ğŸ‘\n",
      "íŒ½ì´ë²„ì„¯ ìœ ì‚°ê·  ë°œíš¨ì•¡ì´ ë“¤ì–´ê°€ì„œ\n",
      "ê¾¸ì¤€í•˜ê²Œ ë§ˆì‹œë©´ í™”ì¥ì‹¤ ê°€ëŠ”ê²Œ\n",
      "í¸í•´ì§€ë„¤ìš”ã…ã…\n"
     ]
    }
   ],
   "source": [
    "# ìš”ì•½\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Komoran\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import kss\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "for document in my_top_df['gdasCont'].head(5):\n",
    "    # Okt ê°ì²´ ìƒì„±\n",
    "    okt = Okt()\n",
    "\n",
    "    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬\n",
    "    sentences = kss.split_sentences(document)\n",
    "\n",
    "    # ê° ë¬¸ì¥ì—ì„œ ëª…ì‚¬, í˜•ìš©ì‚¬, ë™ì‚¬ë§Œ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
    "    words_list = []\n",
    "    for sentence in sentences:\n",
    "        words = okt.pos(sentence, stem=True)\n",
    "        words = [word[0] for word in words if word[1] in ['Noun', 'Adjective', 'Verb']]\n",
    "        words_list.append(' '.join(words))\n",
    "\n",
    "    # TF-IDFë¥¼ ê³„ì‚°í•˜ì—¬ ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform(words_list)\n",
    "    similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
    "\n",
    "    # TextRank ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ë¬¸ì„œ ìš”ì•½\n",
    "    def summarize(document, num_sentences=3):\n",
    "\n",
    "\n",
    "        # ê° ë¬¸ì¥ì—ì„œ ëª…ì‚¬, í˜•ìš©ì‚¬, ë™ì‚¬ë§Œ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
    "        words_list = []\n",
    "        for sentence in sentences:\n",
    "            words = okt.pos(sentence, stem=True)\n",
    "            words = [word[0] for word in words if word[1] in ['Noun', 'Adjective', 'Verb']]\n",
    "            words_list.append(' '.join(words))\n",
    "\n",
    "        # TF-IDFë¥¼ ê³„ì‚°í•˜ì—¬ ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf = vectorizer.fit_transform(words_list)\n",
    "        similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
    "\n",
    "        # TextRank ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ë¬¸ì„œ ìš”ì•½\n",
    "        similarity_graph = similarity_matrix\n",
    "        nx_graph = nx.from_numpy_array(similarity_graph)\n",
    "        scores = nx.pagerank(nx_graph)\n",
    "\n",
    "        # í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ\n",
    "        ranked_sentences = sorted(((score, index) for index, score in scores.items()), reverse=True)\n",
    "        selected_sentences = [sentences[index] for _, index in ranked_sentences[:num_sentences]]\n",
    "        return ' '.join(selected_sentences)\n",
    "\n",
    "    # ë¬¸ì„œ ìš”ì•½\n",
    "    summary = summarize(document, num_sentences=3)\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•˜ì§€ë§Œ ì œì…ì—” ë§ì´ ë‹¬ì•„ìš” ì‹ ë‘ì´ 30gì§œë¦¬ë¥¼ í•˜ë£¨ì— ë‘ë´‰ì§€ì”©  ë¨¹ë„¤ìš” ì œê°€ ìµœê·¼ì— ì˜¬ë¦¬ë¸Œì˜ì—ì„œ ê°€ì¥ ë§ì´  êµ¬ë§¤ë¥¼ í–ˆë˜ ì œí’ˆì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤\n",
      "ê·¸ë˜ë„ 1+1 í–‰ì‚¬ë¥¼ í•˜ê¸¸ë˜ êµ¬ë§¤ë¥¼  í–ˆëŠ”ë° ê²‰ì— ë¬»ì€ ê°€ë£¨ë¥¼ í„¸ì–´ë‚´ê³   ë¨¹ì–´ì•¼ í•´ìš” í—ˆë¸Œì íŠ¸ ë¯¹ìŠ¤ë„›ì€ ê²¬ê³¼ë¥˜êµ¬ì„±ì€  ë§˜ì— ë“œëŠ”ë° ë„˜ì§œìš”\n",
      "ì œê°€ 5ë…„ì„ ë„˜ê²Œ ë§ˆì‹œê³  ìˆëŠ”ë° ê¾¸ì¤€í•˜ê²Œ  ë§ˆì‹œë©´ í™”ì¥ì‹¤ ê°€ëŠ”ê²Œ í¸í•´ì ¸ì„œ ì¢‹ì•„ìš” ì•„ì¹¨ì— ì£¼ë¡œ ë§ˆì‹œê³  ìˆëŠ” ì‚¬ê³¼ë‹¹ê·¼ë§›  ì´ë„ˆì£¼ìŠ¤ì…ë‹ˆë‹¤\n",
      "ì‹ ë‘ì„ ì¤„ë ¤ê³  ì‹ ì²­ì„ í–ˆì–´ìš”~ ì¼ë‹¨ í–¥ë„ ì¤‘ìš”í•˜ì§€ë§Œ ì§€ì†ë ¥ë„ ì¢‹ì•„ì•¼  í•´ì„œ ì‹ ë‘ì´ ë¿Œë¦¬ê³  í•œë‘ì‹œê°„ ì§€ë‚˜ì„œë„  í–¥ì´ ë‚˜ëŠ”ì§€ ì˜†ì— ê°€ë´¤ë”ë‹ˆ ì§„í•˜ê²ŒëŠ”  ì•„ë‹ˆì§€ë§Œ ì€ì€í•˜ê²Œ ì”í–¥ì´ ë‚¨ì•„ ìˆëŠ”ë“¯  í•˜ë„¤ìš”ğŸ˜ ë‚˜ì´ì™€ ìƒê´€ì—†ì´ ëª¨ë“  ì—°ë ¹ì¸µì´ ì‚¬ìš©í•˜ê¸°ì—  ê´œì°®ì€ ì œí’ˆì¸ë“¯ í•©ë‹ˆë‹¤ğŸ‘\n",
      "íŒ½ì´ë²„ì„¯ ìœ ì‚°ê·  ë°œíš¨ì•¡ì´ ë“¤ì–´ê°€ì„œ  ê¾¸ì¤€í•˜ê²Œ ë§ˆì‹œë©´ í™”ì¥ì‹¤ ê°€ëŠ”ê²Œ  í¸í•´ì§€ë„¤ìš”\n"
     ]
    }
   ],
   "source": [
    "# ìš”ì•½2\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Komoran\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import kss\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "for document in my_top_df['gdasCont'].head(5):\n",
    "    # Okt ê°ì²´ ìƒì„±\n",
    "    okt = Okt()\n",
    "    \n",
    "    # ì´ˆì„±, ì¤„ë°”ê¿ˆ ì œê±°\n",
    "    document = re.sub('[ã„±-ã…ã…-ã…£]', '', document)\n",
    "    document = re.sub('[\\r\\n]', ' ', document)\n",
    "    \n",
    "    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬\n",
    "    sentences = kss.split_sentences(document)\n",
    "    \n",
    "    # ê° ë¬¸ì¥ì—ì„œ ëª…ì‚¬, í˜•ìš©ì‚¬, ë™ì‚¬ë§Œ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
    "    words_list = []\n",
    "    for sentence in sentences:\n",
    "        words = okt.pos(sentence, stem=True)\n",
    "        words = [word[0] for word in words if word[1] in ['Noun', 'Adjective', 'Verb']]\n",
    "        words_list.append(' '.join(words))\n",
    "\n",
    "    # TF-IDFë¥¼ ê³„ì‚°í•˜ì—¬ ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform(words_list)\n",
    "    similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
    "\n",
    "    # TextRank ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ë¬¸ì„œ ìš”ì•½\n",
    "    def summarize(document, num_sentences=3):\n",
    "\n",
    "\n",
    "        # ê° ë¬¸ì¥ì—ì„œ ëª…ì‚¬, í˜•ìš©ì‚¬, ë™ì‚¬ë§Œ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
    "        words_list = []\n",
    "        for sentence in sentences:\n",
    "            words = okt.pos(sentence, stem=True)\n",
    "            words = [word[0] for word in words if word[1] in ['Noun', 'Adjective', 'Verb']]\n",
    "            words_list.append(' '.join(words))\n",
    "\n",
    "        # TF-IDFë¥¼ ê³„ì‚°í•˜ì—¬ ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf = vectorizer.fit_transform(words_list)\n",
    "        similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
    "\n",
    "        # TextRank ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ë¬¸ì„œ ìš”ì•½\n",
    "        similarity_graph = similarity_matrix\n",
    "        nx_graph = nx.from_numpy_array(similarity_graph)\n",
    "        scores = nx.pagerank(nx_graph)\n",
    "\n",
    "        # í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ\n",
    "        ranked_sentences = sorted(((score, index) for index, score in scores.items()), reverse=True)\n",
    "        selected_sentences = [sentences[index] for _, index in ranked_sentences[:num_sentences]]\n",
    "        return ' '.join(selected_sentences)\n",
    "\n",
    "    # ë¬¸ì„œ ìš”ì•½\n",
    "    summary = summarize(document, num_sentences=3)\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FACE WITH TEARS OF JOY\n"
     ]
    }
   ],
   "source": [
    "# ì´ëª¨í‹°ì½˜\n",
    "import unicodedata\n",
    "print(unicodedata.name('ğŸ˜‚'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newprj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37dcb171acb47c3d04f804a42efe3935da75a96b4220c54673b89fccb59f3177"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
